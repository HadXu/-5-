{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    start_time = time.time()\n",
    "    yield\n",
    "    print(f'[{name} done in {time.time() - start_time:.2f} s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train finished........\n",
      "finished create embedding.....\n",
      "finished create X,y ................ \n",
      "finished loading X_test ................ \n"
     ]
    }
   ],
   "source": [
    "def zuhe(line):\n",
    "    line['hour'] = line['hour'].astype(str)\n",
    "    line['weekday'] = line['weekday'].astype(str)\n",
    "    line['s_ij'] = line['s_ij'].astype(str)\n",
    "    line['e_ij'] = line['e_ij'].astype(str)\n",
    "\n",
    "#     line['is_peek'] = line['is_peek'].astype(str)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(str)\n",
    "                                   \n",
    "    line['hour_weekday'] = line['hour'] + line['weekday']\n",
    "    line['hour_crowd'] = line['hour'] + line['is_crowd']\n",
    "    line['hour_s'] = line['hour'] + line['s_ij']\n",
    "    line['hour_e'] = line['hour'] + line['e_ij']\n",
    "\n",
    "    line['hour'] = line['hour'].astype(int)\n",
    "#     line['is_peek'] = line['is_peek'].astype(int)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(int)\n",
    "    line['weekday'] = line['weekday'].astype(int)\n",
    "    line['s_ij'] = line['s_ij'].astype(int)\n",
    "    line['e_ij'] = line['e_ij'].astype(int)\n",
    "    \n",
    "    line['hour_weekday'] = line['hour_weekday'].astype(int)\n",
    "    line['hour_crowd'] = line['hour_crowd'].astype(int)\n",
    "    line['hour_s'] = line['hour_s'].astype(int)\n",
    "    line['hour_e'] = line['hour_e'].astype(int)\n",
    "    return line\n",
    "\n",
    "with open('./data/train-id4-crowd-grid3.txt', 'rb') as data_file:\n",
    "    line = pickle.load(data_file)\n",
    "    line = zuhe(line)\n",
    "line = line[(line['Diff_Time']<600)]\n",
    "line['ID'] = line['ID'].astype('category')\n",
    "line['s_ij'] = line['s_ij'].astype('category') \n",
    "line['e_ij'] = line['e_ij'].astype('category')\n",
    "print('read train finished........')\n",
    "\n",
    "info = pd.read_csv('data/all_svd_info.csv',index_col=0)\n",
    "\n",
    "k_pca_1 = KernelPCA(n_components=128)\n",
    "k_pca_1.fit(info)\n",
    "embedding_res = k_pca_1.transform(info)\n",
    "embedding_res = pd.DataFrame(data=embedding_res,index=info.index)\n",
    "\n",
    "print('finished create embedding.....')\n",
    "\n",
    "train = pd.merge(line, embedding_res, how='left', left_on='O_LINENO',right_index=True)\n",
    "col = [c for c in train if\n",
    "       c not in ['Unnamed: 0','ID2','s_x', 's_y', 'e_x', 'e_y','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station','O_TIME', 'aver_v','max_v', 'Diff_Time']]\n",
    "X = train[col]\n",
    "y = train['Diff_Time'].values\n",
    "# y_norm = y / 600\n",
    "\n",
    "print('finished create X,y ................ ')\n",
    "\n",
    "with open('./data/test-id4-crowd-grid3.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "test = pd.merge(test, embedding_res, how='left', left_on='O_LINENO',right_index=True)\n",
    "col1 = [c for c in test if\n",
    "       c not in ['Unnamed: 0','ID2' , 's_x', 's_y', 'e_x', 'e_y','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time','Distance1', 'distance2','TERMINALNO', 'new_dist']]\n",
    "X_test = test[col1]\n",
    "\n",
    "print('finished loading X_test ................ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(X,y,X_test,n_folds):\n",
    "    \n",
    "    def mse_v2(y_pred, train_data):\n",
    "        y_true = train_data.get_label()\n",
    "        return 'rmse', 600*(np.mean((y_pred-y_true)**2))**0.5, False\n",
    "        \n",
    "    from sklearn.model_selection import StratifiedKFold, KFold\n",
    "    print(\"folding\")\n",
    "    kf = KFold(n_splits=n_folds,shuffle=True,random_state=2018)\n",
    "    result = np.zeros((len(X_test), 1))\n",
    "    print(\"training\")\n",
    "    count = 0\n",
    "    for (tr_idx, val_idx) in kf.split(y):\n",
    "        X_train = X.iloc[tr_idx]\n",
    "        y_train = y[tr_idx]\n",
    "\n",
    "        X_dev = X.iloc[val_idx]\n",
    "        y_dev = y[val_idx]\n",
    "        \n",
    "        print(X_train.shape)\n",
    "        print(X_dev.shape)\n",
    "        \n",
    "        lgb_train  = lgb.Dataset(X_train, y_train,)#feature_name=col,categorical_feature=['ID']\n",
    "        lgb_eval = lgb.Dataset(X_dev, y_dev,reference=lgb_train)\n",
    "        params = {'num_leaves':60, \n",
    "                  'max_depth':8,\n",
    "                  'seed':2018,\n",
    "                  'colsample_bytree':0.5,\n",
    "                  'subsample':0.9,\n",
    "                  'num_threads':32,\n",
    "                  'n_estimators':20000,\n",
    "                  'learning_rate': 0.1,\n",
    "                  #'objective':'regression_l2',  \n",
    "                  'objective': 'mse',\n",
    "                  'metric':'rmse',\n",
    "                'device_type':'gpu',\n",
    "                 }\n",
    "        print(count)\n",
    "        gbm = lgb.train(params, lgb_train,early_stopping_rounds=200,valid_sets=lgb_eval,\n",
    "                        verbose_eval=50,\n",
    "                        #feval=mse_v2\n",
    "                       )\n",
    "        \n",
    "        if n_fold==0:\n",
    "            feature_score = pd.DataFrame()\n",
    "            feature_score['name'] = gbm.feature_name()\n",
    "            feature_score['importance1'] = gbm.feature_importance()\n",
    "            feature_score['importance2'] = gbm.feature_importance('gain')\n",
    "            feature_score['importance3'] = feature_score['importance2']/(feature_score['importance1']**0.5)\n",
    "            feature_score.dropna(inplace=True)\n",
    "            feature_score = feature_score.sort_values(by=['importance3','importance2','importance1'],ascending=False)\n",
    "            print(feature_score)\n",
    "            \n",
    "        resultx = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        resultx = np.reshape(resultx,(490380, 1))\n",
    "        print(resultx.shape,result.shape)\n",
    "        result = result + resultx\n",
    "        y_te_pred = gbm.predict(X_dev, num_iteration=gbm.best_iteration)\n",
    "        #print(log_loss(y_dev, y_te_pred))\n",
    "\n",
    "        count = count+1\n",
    "    # 提交结果\n",
    "    result /= n_folds\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folding\n",
      "training\n",
      "(12360197, 151)\n",
      "(1373356, 151)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/.local/lib/python3.6/site-packages/lightgbm/engine.py:105: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[50]\tvalid_0's rmse: 39.8349\n",
      "[100]\tvalid_0's rmse: 39.0357\n",
      "[150]\tvalid_0's rmse: 38.7489\n",
      "[200]\tvalid_0's rmse: 38.5946\n",
      "[250]\tvalid_0's rmse: 38.4736\n",
      "[300]\tvalid_0's rmse: 38.3943\n",
      "[350]\tvalid_0's rmse: 38.3141\n",
      "[400]\tvalid_0's rmse: 38.2519\n",
      "[450]\tvalid_0's rmse: 38.2013\n",
      "[500]\tvalid_0's rmse: 38.1466\n",
      "[550]\tvalid_0's rmse: 38.0982\n",
      "[600]\tvalid_0's rmse: 38.0562\n",
      "[650]\tvalid_0's rmse: 38.0106\n",
      "[700]\tvalid_0's rmse: 37.9837\n",
      "[750]\tvalid_0's rmse: 37.9476\n",
      "[800]\tvalid_0's rmse: 37.9154\n",
      "[850]\tvalid_0's rmse: 37.8862\n",
      "[900]\tvalid_0's rmse: 37.8563\n",
      "[950]\tvalid_0's rmse: 37.8246\n",
      "[1000]\tvalid_0's rmse: 37.7979\n",
      "[1050]\tvalid_0's rmse: 37.7693\n",
      "[1100]\tvalid_0's rmse: 37.7418\n",
      "[1150]\tvalid_0's rmse: 37.7158\n",
      "[1200]\tvalid_0's rmse: 37.6866\n",
      "[1250]\tvalid_0's rmse: 37.6573\n",
      "[1300]\tvalid_0's rmse: 37.6373\n",
      "[1350]\tvalid_0's rmse: 37.6168\n",
      "[1400]\tvalid_0's rmse: 37.5933\n",
      "[1450]\tvalid_0's rmse: 37.5717\n",
      "[1500]\tvalid_0's rmse: 37.5511\n",
      "[1550]\tvalid_0's rmse: 37.5309\n",
      "[1600]\tvalid_0's rmse: 37.51\n",
      "[1650]\tvalid_0's rmse: 37.4928\n",
      "[1700]\tvalid_0's rmse: 37.4761\n",
      "[1750]\tvalid_0's rmse: 37.4612\n",
      "[1800]\tvalid_0's rmse: 37.4427\n",
      "[1850]\tvalid_0's rmse: 37.4298\n",
      "[1900]\tvalid_0's rmse: 37.4153\n",
      "[1950]\tvalid_0's rmse: 37.4007\n",
      "[2000]\tvalid_0's rmse: 37.3832\n",
      "[2050]\tvalid_0's rmse: 37.3686\n",
      "[2100]\tvalid_0's rmse: 37.3549\n",
      "[2150]\tvalid_0's rmse: 37.3348\n",
      "[2200]\tvalid_0's rmse: 37.3229\n",
      "[2250]\tvalid_0's rmse: 37.3086\n",
      "[2300]\tvalid_0's rmse: 37.2961\n",
      "[2350]\tvalid_0's rmse: 37.2836\n",
      "[2400]\tvalid_0's rmse: 37.2706\n",
      "[2450]\tvalid_0's rmse: 37.259\n",
      "[2500]\tvalid_0's rmse: 37.2467\n",
      "[2550]\tvalid_0's rmse: 37.2342\n",
      "[2600]\tvalid_0's rmse: 37.2234\n",
      "[2650]\tvalid_0's rmse: 37.2116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1975b05cdc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-68b5bf4ce527>\u001b[0m in \u001b[0;36mtrain2\u001b[0;34m(X, y, X_test, n_folds)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         gbm = lgb.train(params, lgb_train,early_stopping_rounds=200,valid_sets=lgb_eval,\n\u001b[0;32m---> 40\u001b[0;31m                         \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0;31m#feval=mse_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                        )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1568\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1569\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred = train2(X,y,X_test,n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0          ID  O_LINENO  O_UP  Source_Station  \\\n",
      "0                  1    80412021       804     1              20   \n",
      "1                  2    80412122       804     1              21   \n",
      "2                  3    80412223       804     1              22   \n",
      "3                  4    80412324       804     1              23   \n",
      "4                  5    80412425       804     1              24   \n",
      "6                  7    80400304       804     0               3   \n",
      "7                  8    80400405       804     0               4   \n",
      "8                  9    80400506       804     0               5   \n",
      "9                 10    80400607       804     0               6   \n",
      "10                11    80400708       804     0               7   \n",
      "11                12    80400809       804     0               8   \n",
      "12                13    80400910       804     0               9   \n",
      "13                14    80401011       804     0              10   \n",
      "14                15    80401112       804     0              11   \n",
      "15                16    80401213       804     0              12   \n",
      "16                17    80401314       804     0              13   \n",
      "17                18    80401415       804     0              14   \n",
      "18                19    80401516       804     0              15   \n",
      "19                20    80401617       804     0              16   \n",
      "20                21    80401718       804     0              17   \n",
      "21                22    80401819       804     0              18   \n",
      "22                23    80401920       804     0              19   \n",
      "23                24    80402021       804     0              20   \n",
      "24                25    80402122       804     0              21   \n",
      "25                26    80402223       804     0              22   \n",
      "26                28    80410203       804     1               2   \n",
      "27                29    80410304       804     1               3   \n",
      "28                30    80410405       804     1               4   \n",
      "29                31    80410506       804     1               5   \n",
      "30                32    80410607       804     1               6   \n",
      "...              ...         ...       ...   ...             ...   \n",
      "13963704          38  5501102021     55011     0              20   \n",
      "13963705          39  5501102122     55011     0              21   \n",
      "13963706          40  5501102223     55011     0              22   \n",
      "13963707          41  5501102324     55011     0              23   \n",
      "13963709           1  5501210203     55012     1               2   \n",
      "13963710           2  5501210304     55012     1               3   \n",
      "13963712           4  5501210506     55012     1               5   \n",
      "13963713           6  5501210708     55012     1               7   \n",
      "13963714           7  5501210809     55012     1               8   \n",
      "13963715           9  5501200203     55012     0               2   \n",
      "13963716          10  5501200304     55012     0               3   \n",
      "13963719          13  5501200607     55012     0               6   \n",
      "13963720          14  5501200708     55012     0               7   \n",
      "13963721          15  5501200809     55012     0               8   \n",
      "13963722          17  5501210405     55012     1               4   \n",
      "13963725          20  5501210708     55012     1               7   \n",
      "13963726          21  5501210809     55012     1               8   \n",
      "13963728          24  5501200304     55012     0               3   \n",
      "13963731          27  5501200607     55012     0               6   \n",
      "13963732          28  5501200708     55012     0               7   \n",
      "13963733          29  5501200809     55012     0               8   \n",
      "13963734           1  5500910203     55009     1               2   \n",
      "13963735           2  5500910304     55009     1               3   \n",
      "13963737           4  5500910506     55009     1               5   \n",
      "13963738           6  5500900203     55009     0               2   \n",
      "13963740           8  5500900405     55009     0               4   \n",
      "13963741           9  5500900506     55009     0               5   \n",
      "13963742          11  5500910203     55009     1               2   \n",
      "13963743          12  5500910304     55009     1               3   \n",
      "13963745          15  5500900506     55009     0               5   \n",
      "\n",
      "          Target_Station  Distance               O_TIME     aver_v  hour  \\\n",
      "0                     21  0.629329  2017-10-09 06:31:28  16.182736     6   \n",
      "1                     22  0.983431  2017-10-09 06:35:18  15.392834     6   \n",
      "2                     23  0.690608  2017-10-09 06:36:28  35.516963     6   \n",
      "3                     24  0.608654  2017-10-09 06:37:38  31.302190     6   \n",
      "4                     25  0.362356  2017-10-09 06:38:28  26.089661     6   \n",
      "6                      4  0.846219  2017-10-09 07:00:04  27.948529     7   \n",
      "7                      5  0.556623  2017-10-09 07:04:04   8.349346     7   \n",
      "8                      6  0.582659  2017-10-09 07:05:54  19.068836     7   \n",
      "9                      7  1.290634  2017-10-09 07:09:34  21.119466     7   \n",
      "10                     8  0.590267  2017-10-09 07:12:04  14.166414     7   \n",
      "11                     9  1.402541  2017-10-09 07:16:34  18.700553     7   \n",
      "12                    10  0.383117  2017-10-09 07:19:14   8.620134     7   \n",
      "13                    11  1.253965  2017-10-09 07:23:24  18.057099     7   \n",
      "14                    12  1.246375  2017-10-09 07:25:24  37.391249     7   \n",
      "15                    13  1.090529  2017-10-09 07:28:04  24.536897     7   \n",
      "16                    14  1.150083  2017-10-09 07:30:14  31.848439     7   \n",
      "17                    15  1.945770  2017-10-09 07:38:04  14.903773     7   \n",
      "18                    16  1.859327  2017-10-09 07:42:14  26.774313     7   \n",
      "19                    17  0.644827  2017-10-09 07:43:34  29.017212     7   \n",
      "20                    18  1.593767  2017-10-09 07:45:54  40.982582     7   \n",
      "21                    19  2.541232  2017-10-09 07:50:14  35.186294     7   \n",
      "22                    20  3.175953  2017-10-09 07:56:44  29.316490     7   \n",
      "23                    21  1.803431  2017-10-09 08:00:54  25.969412     8   \n",
      "24                    22  1.722122  2017-10-09 08:04:24  29.522092     8   \n",
      "25                    23  0.790112  2017-10-09 08:05:54  31.604478     8   \n",
      "26                     3  0.887927  2017-10-09 08:34:54  35.517066     8   \n",
      "27                     4  1.609496  2017-10-09 08:37:44  34.083455     8   \n",
      "28                     5  1.823528  2017-10-09 08:42:14  24.313703     8   \n",
      "29                     6  3.352708  2017-10-09 08:48:15  33.434211     8   \n",
      "30                     7  2.484500  2017-10-09 08:51:54  40.841101     8   \n",
      "...                  ...       ...                  ...        ...   ...   \n",
      "13963704              21  0.602207  2017-10-24 18:30:47  14.452962    18   \n",
      "13963705              22  0.260813  2017-10-24 18:31:24  25.376370    18   \n",
      "13963706              23  0.838817  2017-10-24 18:33:54  20.131611    18   \n",
      "13963707              24  0.355353  2017-10-24 18:35:33  12.921938    18   \n",
      "13963709               3  0.426279  2017-10-24 06:53:48  13.825264     6   \n",
      "13963710               4  2.566864  2017-10-24 06:57:38  40.176998     6   \n",
      "13963712               6  4.788964  2017-10-24 07:17:40  29.724605     7   \n",
      "13963713               8  1.726842  2017-10-24 07:33:30  25.902628     7   \n",
      "13963714               9  2.767412  2017-10-24 07:42:10  19.159004     7   \n",
      "13963715               3  2.717734  2017-10-24 17:41:26  18.118227    17   \n",
      "13963716               4  1.932335  2017-10-24 17:47:56  17.836937    17   \n",
      "13963719               7  6.115170  2017-10-24 18:22:34  49.249693    18   \n",
      "13963720               8  1.538402  2017-10-24 18:26:44  22.152986    18   \n",
      "13963721               9  1.308323  2017-10-24 18:30:25  21.312047    18   \n",
      "13963722               5  6.609656  2017-10-24 07:27:17  44.811227     7   \n",
      "13963725               8  1.720030  2017-10-24 08:01:00  20.640357     8   \n",
      "13963726               9  2.750191  2017-10-24 08:09:00  20.626431     8   \n",
      "13963728               4  2.010180  2017-10-24 18:07:38  18.091622    18   \n",
      "13963731               7  6.152744  2017-10-24 18:41:25  55.793142    18   \n",
      "13963732               8  1.497825  2017-10-24 18:43:55  35.947791    18   \n",
      "13963733               9  1.402856  2017-10-24 18:47:45  21.957751    18   \n",
      "13963734               3  0.477920  2017-10-24 07:24:50  15.641033     7   \n",
      "13963735               4  3.363145  2017-10-24 07:30:23  36.358327     7   \n",
      "13963737               6  0.788507  2017-10-24 07:44:59  21.835576     7   \n",
      "13963738               3  0.986650  2017-10-24 17:33:48  20.893759    17   \n",
      "13963740               5  3.787491  2017-10-24 17:59:56  33.256017    17   \n",
      "13963741               6  0.418466  2017-10-24 18:01:36  15.064780    18   \n",
      "13963742               3  0.524619  2017-10-24 07:36:01  12.590863     7   \n",
      "13963743               4  3.320681  2017-10-24 07:41:18  37.711207     7   \n",
      "13963745               6  0.444309  2017-10-24 18:23:39  12.303939    18   \n",
      "\n",
      "            ...          118       119       120       121       122  \\\n",
      "0           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "1           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "2           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "3           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "4           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "6           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "7           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "8           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "9           ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "10          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "11          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "12          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "13          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "14          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "15          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "16          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "17          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "18          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "19          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "20          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "21          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "22          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "23          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "24          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "25          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "26          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "27          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "28          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "29          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "30          ...     0.198515 -0.151538 -0.025367 -0.024916 -0.106380   \n",
      "...         ...          ...       ...       ...       ...       ...   \n",
      "13963704    ...    -0.105840  0.082376  0.014112  0.013888  0.059587   \n",
      "13963705    ...    -0.105840  0.082376  0.014112  0.013888  0.059587   \n",
      "13963706    ...    -0.105840  0.082376  0.014112  0.013888  0.059587   \n",
      "13963707    ...    -0.105840  0.082376  0.014112  0.013888  0.059587   \n",
      "13963709    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963710    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963712    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963713    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963714    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963715    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963716    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963719    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963720    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963721    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963722    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963725    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963726    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963728    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963731    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963732    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963733    ...    -0.117085  0.095769  0.021289  0.022524  0.148299   \n",
      "13963734    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963735    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963737    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963738    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963740    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963741    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963742    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963743    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "13963745    ...    -0.110830  0.086639  0.014946  0.014718  0.063263   \n",
      "\n",
      "               123       124       125       126       127  \n",
      "0        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "1        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "2        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "3        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "4        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "6        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "7        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "8        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "9        -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "10       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "11       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "12       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "13       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "14       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "15       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "16       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "17       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "18       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "19       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "20       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "21       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "22       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "23       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "24       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "25       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "26       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "27       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "28       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "29       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "30       -0.231144 -0.079665 -0.010163 -0.038492 -0.098850  \n",
      "...            ...       ...       ...       ...       ...  \n",
      "13963704  0.130818  0.046292  0.005971  0.022675  0.058527  \n",
      "13963705  0.130818  0.046292  0.005971  0.022675  0.058527  \n",
      "13963706  0.130818  0.046292  0.005971  0.022675  0.058527  \n",
      "13963707  0.130818  0.046292  0.005971  0.022675  0.058527  \n",
      "13963709  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963710  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963712  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963713  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963714  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963715  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963716  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963719  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963720  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963721  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963722  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963725  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963726  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963728  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963731  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963732  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963733  0.034166  0.039543  0.005330  0.020390  0.053254  \n",
      "13963734  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963735  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963737  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963738  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963740  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963741  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963742  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963743  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "13963745  0.139497  0.050141  0.006530  0.024864  0.064546  \n",
      "\n",
      "[13733553 rows x 165 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
