{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Flatten, Input, concatenate\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Nadam\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zuhe(line):\n",
    "    line['hour'] = line['hour'].astype(str)\n",
    "    line['weekday'] = line['weekday'].astype(str)\n",
    "    line['is_peek'] = line['is_peek'].astype(str)\n",
    "    line['is_workday'] = line['is_workday'].astype(str)\n",
    "                                   \n",
    "    line['hour_weekday'] = line['hour'] + line['weekday']\n",
    "    line['peak_workday'] = line['is_peek'] + line['is_workday']\n",
    "    \n",
    "    line['hour'] = line['hour'].astype(int)\n",
    "    line['is_peek'] = line['is_peek'].astype(int)\n",
    "    line['is_workday'] = line['is_workday'].astype(int)\n",
    "    line['weekday'] = line['weekday'].astype(int)\n",
    "    \n",
    "    line['hour_weekday'] = line['hour_weekday'].astype(int)\n",
    "    line['peak_workday'] = line['peak_workday'].astype(int)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14223933,)\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train-id4-crowd-grid4.txt', 'rb') as data_file:\n",
    "    train = pickle.load(data_file)\n",
    "    #训练验证都划分\n",
    "    #900 29 26 #800 27.9 25.9 #700 27.5 25.3 #27.4 24.8 #26.4 24.08 #23 21 #(90)250 21 19.5 #(80)17. 16.5\n",
    "    #训练划分 验证不划分\n",
    "    #250\n",
    "train = train[(train['Diff_Time']<600)]\n",
    "train = zuhe(train)\n",
    "with open('./data/test-id4-crowd-grid4.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "test = zuhe(test)\n",
    "from sklearn import preprocessing\n",
    "x1 = train['ID'].as_matrix().reshape([-1,1])\n",
    "N1 = x1.shape[0]\n",
    "\n",
    "x2 = test['ID'].as_matrix().reshape([-1,1])\n",
    "N2 = x2.shape[0]\n",
    "x = np.concatenate((x1,x2))\n",
    "x = preprocessing.LabelEncoder().fit_transform(x) #13963746x21567\n",
    "print(x.shape)#(14454126, 21567)\n",
    "train['new_ID'] = x[:N1]\n",
    "test['new_ID'] = x[N1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = ['new_ID']\n",
    "col2 = [c for c in train if\n",
    "       c not in ['Unnamed: 0','ID2', 's_ij', 'e_ij', 's_x', 's_y', 'e_x', 'e_y', 'new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time']]\n",
    "col3 = ['Source_Station_encode']\n",
    "col4 = ['Target_Station_encode']\n",
    "\n",
    "X_train1 = train[col1].values\n",
    "X_train2 = train[col2].values\n",
    "X_train3 = train[col3].values\n",
    "X_train4 = train[col4].values\n",
    "y_train = train['Diff_Time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_ID'] ['Distance', 'hour', 'is_peek', 'weekday', 'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'h_aver_diff', 'h_aver_d', 'h_aver_v', 'is_crowd', 'grid_aver_diff', 'grid_aver_d', 'Source_Station_encode', 'Target_Station_encode', 'hour_weekday', 'peak_workday'] ['Source_Station_encode'] ['Target_Station_encode']\n",
      "test (490380, 1) (490380, 20) (490380, 1) (490380, 1)\n"
     ]
    }
   ],
   "source": [
    "col1 = ['new_ID']\n",
    "col2 = [c for c in test if\n",
    "       c not in ['Unnamed: 0','ID2', 's_ij', 'e_ij', 's_x', 's_y', 'e_x', 'e_y', 'new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time','Distance1', 'distance2','TERMINALNO', 'new_dist']]\n",
    "col3 = ['Source_Station_encode']\n",
    "col4 = ['Target_Station_encode']\n",
    "\n",
    "print(col1,col2,col3,col4)\n",
    "X_test1 = test[col1].values\n",
    "X_test2 = test[col2].values\n",
    "X_test3 = test[col3].values\n",
    "X_test4 = test[col4].values\n",
    "print('test',X_test1.shape,X_test2.shape,X_test3.shape,X_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean((y_pred - y_true)**2))\n",
    "    \n",
    "def mse_loss(y_true,y_pred):\n",
    "    return K.sqrt(K.mean((y_pred - y_true)**2))\n",
    "\n",
    "def get_model():\n",
    "    input1 = Input(shape=(1,))\n",
    "    input2 = Input(shape=(20,))\n",
    "    input3 = Input(shape=(1,))\n",
    "    input4 = Input(shape=(1,))\n",
    "\n",
    "    x1 = Embedding(21064, 128, input_length=1)(input1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    \n",
    "    x2 = BatchNormalization()(input2)\n",
    "    x2 = Dense(units=128,activation='relu')(x2)\n",
    "    \n",
    "    x3 = Embedding(4609, 48, input_length=1)(input3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "    \n",
    "    x4 = Embedding(4609, 48, input_length=1)(input4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Flatten()(x4)\n",
    "\n",
    "    def dist(x):\n",
    "        return x[0]*x[1]/(K.sum(x[0]**2,axis=1,keepdims=True)+K.sum(x[1]**2,axis=1,keepdims=True))    \n",
    "    #     Aggregate\n",
    "    x3_x4 = Lambda(dist)([x3,x4])\n",
    "\n",
    "    x = concatenate([x1, x2, x3, x4, x3_x4])\n",
    "#     x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=[input1, input2, input3, input4], outputs=out)\n",
    "    print(model.summary())\n",
    "    model.compile(loss=mse_loss, optimizer=Nadam(), metrics=[root_mean_squared_error])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "def get_stacking(X_train1, X_train2, X_train3, X_train4, labels, n_folds=10):\n",
    "    train_num, test_num = X_train1.shape[0], X_test1.shape[0]\n",
    "    second_level_train_set = np.zeros((train_num,))\n",
    "    second_level_test_set = np.zeros((test_num,))\n",
    "    test_nfolds_sets = np.zeros((test_num, n_folds))\n",
    "    \n",
    "    folds = KFold(n_splits=n_folds, shuffle=True, random_state=1001001)\n",
    "        \n",
    "    for n_fold,(train_idx, val_idx) in enumerate(folds.split(labels)):\n",
    "        train_1 = X_train1[train_idx]\n",
    "        train_2 = X_train2[train_idx]\n",
    "        train_3 = X_train3[train_idx]\n",
    "        train_4 = X_train4[train_idx]\n",
    "        train_y = labels[train_idx]\n",
    "\n",
    "        val_1 = X_train1[val_idx]\n",
    "        val_2 = X_train2[val_idx]\n",
    "        val_3 = X_train3[val_idx]\n",
    "        val_4 = X_train4[val_idx]\n",
    "        val_y = labels[val_idx]\n",
    "#         ckpt_path = './logtianchi/'+ model_list[n_fold]\n",
    "#         print(ckpt_path)\n",
    "        model = get_model()\n",
    "        if n_fold == 0:\n",
    "            print(model.summary())\n",
    "        print(n_fold)\n",
    "        \n",
    "\n",
    "\n",
    "        ckpt_path = './log/qrfcv_'+str(n_fold)+'_weights-{val_loss:.4f}.hdf5'\n",
    "        \n",
    "        for i in range(10):\n",
    "            model.fit([train_1,train_2,train_3,train_4],train_y+np.random.uniform(-1,1,(len(train_y,))), \n",
    "                      validation_data=([val_1,val_2,val_3,val_4],val_y), \n",
    "                      epochs=1, \n",
    "                      batch_size=1024,\n",
    "    #                   callbacks=[\n",
    "    #                       ModelCheckpoint(ckpt_path,monitor='val_loss',verbose=1,save_best_only=True,mode='min'),\n",
    "    #                       EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')]\n",
    "                     )\n",
    "        \n",
    "        second_level_train_set[val_idx] = model.predict([val_1, val_2,val_3,val_4], batch_size=1024)[:, 0]\n",
    "        test_nfolds_sets[:,n_fold] = model.predict([X_test1, X_test2, X_test3, X_test4], batch_size=1024)[:, 0]\n",
    "    \n",
    "    \"---save---\"\n",
    "    with open('./data/qrf_test_nfolds_sets3.txt', 'wb') as data_file:\n",
    "        pickle.dump(test_nfolds_sets, data_file)\n",
    "\n",
    "    second_level_test_set[:] = test_nfolds_sets.mean(axis=1)\n",
    "\n",
    "    result = second_level_test_set\n",
    "    \n",
    "    return second_level_train_set, second_level_test_set, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 48)        221232      input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 48)        221232      input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 128)       2696192     input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1, 48)        192         embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1, 48)        192         embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 128)          0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 20)           80          input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 48)           0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 48)           0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 128)          512         flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          2688        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 48)           0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 400)          0           batch_normalization_53[0][0]     \n",
      "                                                                 dense_53[0][0]                   \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 512)          205312      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 512)          262656      dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1)            513         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,610,801\n",
      "Trainable params: 3,610,313\n",
      "Non-trainable params: 488\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 48)        221232      input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 48)        221232      input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 128)       2696192     input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1, 48)        192         embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1, 48)        192         embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 128)          0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 20)           80          input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 48)           0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 48)           0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 128)          512         flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          2688        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 48)           0           flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 400)          0           batch_normalization_53[0][0]     \n",
      "                                                                 dense_53[0][0]                   \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 512)          205312      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 512)          262656      dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1)            513         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,610,801\n",
      "Trainable params: 3,610,313\n",
      "Non-trainable params: 488\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/10\n",
      "12360197/12360197 [==============================] - 471s 38us/step - loss: 39.7314 - root_mean_squared_error: 39.7314 - val_loss: 37.4213 - val_root_mean_squared_error: 37.4213\n",
      "Epoch 2/10\n",
      "12360197/12360197 [==============================] - 464s 38us/step - loss: 37.9178 - root_mean_squared_error: 37.9178 - val_loss: 36.7210 - val_root_mean_squared_error: 36.7210\n",
      "Epoch 3/10\n",
      "12360197/12360197 [==============================] - 464s 38us/step - loss: 37.2656 - root_mean_squared_error: 37.2656 - val_loss: 36.7574 - val_root_mean_squared_error: 36.7574\n",
      "Epoch 4/10\n",
      "12360197/12360197 [==============================] - 462s 37us/step - loss: 36.8045 - root_mean_squared_error: 36.8045 - val_loss: 36.1791 - val_root_mean_squared_error: 36.1791\n",
      "Epoch 5/10\n",
      "12360197/12360197 [==============================] - 460s 37us/step - loss: 36.4402 - root_mean_squared_error: 36.4402 - val_loss: 36.7348 - val_root_mean_squared_error: 36.7348\n",
      "Epoch 6/10\n",
      "12360197/12360197 [==============================] - 464s 38us/step - loss: 36.1269 - root_mean_squared_error: 36.1269 - val_loss: 36.1965 - val_root_mean_squared_error: 36.1965\n",
      "Epoch 7/10\n",
      "12360197/12360197 [==============================] - 459s 37us/step - loss: 35.8763 - root_mean_squared_error: 35.8763 - val_loss: 36.5809 - val_root_mean_squared_error: 36.5809\n",
      "Epoch 8/10\n",
      "12360197/12360197 [==============================] - 460s 37us/step - loss: 35.6546 - root_mean_squared_error: 35.6546 - val_loss: 36.3397 - val_root_mean_squared_error: 36.3397\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 1, 48)        221232      input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 48)        221232      input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 128)       2696192     input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1, 48)        192         embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 48)        192         embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 128)          0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 20)           80          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 48)           0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 48)           0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128)          512         flatten_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 128)          2688        batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 48)           0           flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 400)          0           batch_normalization_57[0][0]     \n",
      "                                                                 dense_57[0][0]                   \n",
      "                                                                 flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "                                                                 lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 512)          205312      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 512)          262656      dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            513         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,610,801\n",
      "Trainable params: 3,610,313\n",
      "Non-trainable params: 488\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "1\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/10\n",
      "12360197/12360197 [==============================] - 467s 38us/step - loss: 39.7663 - root_mean_squared_error: 39.7663 - val_loss: 38.3802 - val_root_mean_squared_error: 38.3802\n",
      "Epoch 2/10\n",
      "12360197/12360197 [==============================] - 463s 37us/step - loss: 37.9430 - root_mean_squared_error: 37.9430 - val_loss: 37.9179 - val_root_mean_squared_error: 37.9179\n",
      "Epoch 3/10\n",
      "12360197/12360197 [==============================] - 463s 37us/step - loss: 37.3232 - root_mean_squared_error: 37.3232 - val_loss: 37.2255 - val_root_mean_squared_error: 37.2255\n",
      "Epoch 4/10\n",
      "12360197/12360197 [==============================] - 545s 44us/step - loss: 36.9164 - root_mean_squared_error: 36.9164 - val_loss: 38.0101 - val_root_mean_squared_error: 38.0101\n",
      "Epoch 5/10\n",
      "12360197/12360197 [==============================] - 474s 38us/step - loss: 36.5424 - root_mean_squared_error: 36.5424 - val_loss: 38.1334 - val_root_mean_squared_error: 38.1334\n",
      "Epoch 6/10\n",
      "12360197/12360197 [==============================] - 463s 37us/step - loss: 36.2401 - root_mean_squared_error: 36.2401 - val_loss: 37.6394 - val_root_mean_squared_error: 37.6394\n",
      "Epoch 7/10\n",
      "12360197/12360197 [==============================] - 465s 38us/step - loss: 35.9804 - root_mean_squared_error: 35.9804 - val_loss: 37.0643 - val_root_mean_squared_error: 37.0643\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12360197/12360197 [==============================] - 463s 37us/step - loss: 35.7968 - root_mean_squared_error: 35.7968 - val_loss: 37.1291 - val_root_mean_squared_error: 37.1291\n",
      "Epoch 9/10\n",
      "12360197/12360197 [==============================] - 259s 21us/step - loss: 35.5974 - root_mean_squared_error: 35.5974 - val_loss: 38.2429 - val_root_mean_squared_error: 38.2429\n",
      "Epoch 10/10\n",
      "11553792/12360197 [===========================>..] - ETA: 14s - loss: 35.3909 - root_mean_squared_error: 35.3909"
     ]
    }
   ],
   "source": [
    "train_sets = []\n",
    "test_sets = []\n",
    "train_set, test_set, result = get_stacking(X_train1, X_train2, X_train3, X_train4, y_train, n_folds=10)\n",
    "train_sets.append(train_set)\n",
    "test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
