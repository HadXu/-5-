{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Flatten, Input, concatenate\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Nadam\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zuhe(line):\n",
    "    line['hour'] = line['hour'].astype(str)\n",
    "    line['weekday'] = line['weekday'].astype(str)\n",
    "    line['is_peek'] = line['is_peek'].astype(str)\n",
    "    line['is_workday'] = line['is_workday'].astype(str)\n",
    "                                   \n",
    "    line['hour_weekday'] = line['hour'] + line['weekday']\n",
    "    line['peak_workday'] = line['is_peek'] + line['is_workday']\n",
    "    \n",
    "    line['hour'] = line['hour'].astype(int)\n",
    "    line['is_peek'] = line['is_peek'].astype(int)\n",
    "    line['is_workday'] = line['is_workday'].astype(int)\n",
    "    line['weekday'] = line['weekday'].astype(int)\n",
    "    \n",
    "    line['hour_weekday'] = line['hour_weekday'].astype(int)\n",
    "    line['peak_workday'] = line['peak_workday'].astype(int)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14223933,)\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train-id4-crowd-grid4.txt', 'rb') as data_file:\n",
    "    train = pickle.load(data_file)\n",
    "    #训练验证都划分\n",
    "    #900 29 26 #800 27.9 25.9 #700 27.5 25.3 #27.4 24.8 #26.4 24.08 #23 21 #(90)250 21 19.5 #(80)17. 16.5\n",
    "    #训练划分 验证不划分\n",
    "    #250\n",
    "train = train[(train['Diff_Time']<600)]\n",
    "train = zuhe(train)\n",
    "with open('./data/test-id4-crowd-grid4.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "test = zuhe(test)\n",
    "from sklearn import preprocessing\n",
    "x1 = train['ID'].as_matrix().reshape([-1,1])\n",
    "N1 = x1.shape[0]\n",
    "\n",
    "x2 = test['ID'].as_matrix().reshape([-1,1])\n",
    "N2 = x2.shape[0]\n",
    "x = np.concatenate((x1,x2))\n",
    "x = preprocessing.LabelEncoder().fit_transform(x) #13963746x21567\n",
    "print(x.shape)#(14454126, 21567)\n",
    "train['new_ID'] = x[:N1]\n",
    "test['new_ID'] = x[N1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = ['new_ID']\n",
    "col2 = [c for c in train if\n",
    "       c not in ['Unnamed: 0','ID2', 's_ij', 'e_ij', 's_x', 's_y', 'e_x', 'e_y', 'new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time']]\n",
    "col3 = ['Source_Station_encode']\n",
    "col4 = ['Target_Station_encode']\n",
    "\n",
    "X_train1 = train[col1].values\n",
    "X_train2 = train[col2].values\n",
    "X_train3 = train[col3].values\n",
    "X_train4 = train[col4].values\n",
    "y_train = train['Diff_Time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_ID'] ['Distance', 'hour', 'is_peek', 'weekday', 'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'h_aver_diff', 'h_aver_d', 'h_aver_v', 'is_crowd', 'grid_aver_diff', 'grid_aver_d', 'Source_Station_encode', 'Target_Station_encode', 'hour_weekday', 'peak_workday'] ['Source_Station_encode'] ['Target_Station_encode']\n",
      "test (490380, 1) (490380, 20) (490380, 1) (490380, 1)\n"
     ]
    }
   ],
   "source": [
    "col1 = ['new_ID']\n",
    "col2 = [c for c in test if\n",
    "       c not in ['Unnamed: 0','ID2', 's_ij', 'e_ij', 's_x', 's_y', 'e_x', 'e_y', 'new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time','Distance1', 'distance2','TERMINALNO', 'new_dist']]\n",
    "col3 = ['Source_Station_encode']\n",
    "col4 = ['Target_Station_encode']\n",
    "\n",
    "print(col1,col2,col3,col4)\n",
    "X_test1 = test[col1].values\n",
    "X_test2 = test[col2].values\n",
    "X_test3 = test[col3].values\n",
    "X_test4 = test[col4].values\n",
    "print('test',X_test1.shape,X_test2.shape,X_test3.shape,X_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean((y_pred - y_true)**2))\n",
    "    \n",
    "def mse_loss(y_true,y_pred):\n",
    "    return K.sqrt(K.mean((y_pred - y_true)**2))\n",
    "\n",
    "def get_model():\n",
    "    input1 = Input(shape=(1,))\n",
    "    input2 = Input(shape=(20,))\n",
    "    input3 = Input(shape=(1,))\n",
    "    input4 = Input(shape=(1,))\n",
    "\n",
    "    x1 = Embedding(21064, 128, input_length=1)(input1)\n",
    "    x1 = Flatten()(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    \n",
    "    x2 = BatchNormalization()(input2)\n",
    "    x2 = Dense(units=128,activation='relu')(x2)\n",
    "    \n",
    "    x3 = Embedding(4609, 48, input_length=1)(input3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "    \n",
    "    x4 = Embedding(4609, 48, input_length=1)(input4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Flatten()(x4)\n",
    "\n",
    "    def dist(x):\n",
    "        return x[0]*x[1]/(K.sum(x[0]**2,axis=1,keepdims=True)+K.sum(x[1]**2,axis=1,keepdims=True))    \n",
    "    #     Aggregate\n",
    "    x3_x4 = Lambda(dist)([x3,x4])\n",
    "\n",
    "    x = concatenate([x1, x2, x3, x4, x3_x4])\n",
    "#     x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=[input1, input2, input3, input4], outputs=out)\n",
    "    model.compile(loss=mse_loss, optimizer=Nadam(), metrics=[root_mean_squared_error])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "def get_stacking(X_train1, X_train2, X_train3, X_train4, labels, n_folds=10):\n",
    "    train_num, test_num = X_train1.shape[0], X_test1.shape[0]\n",
    "    second_level_train_set = np.zeros((train_num,))\n",
    "    second_level_test_set = np.zeros((test_num,))\n",
    "    test_nfolds_sets = np.zeros((test_num, n_folds))\n",
    "    \n",
    "    folds = KFold(n_splits=n_folds, shuffle=True, random_state=1001001)\n",
    "        \n",
    "    for n_fold,(train_idx, val_idx) in enumerate(folds.split(labels)):\n",
    "        train_1 = X_train1[train_idx]\n",
    "        train_2 = X_train2[train_idx]\n",
    "        train_3 = X_train3[train_idx]\n",
    "        train_4 = X_train4[train_idx]\n",
    "        train_y = labels[train_idx]\n",
    "\n",
    "        val_1 = X_train1[val_idx]\n",
    "        val_2 = X_train2[val_idx]\n",
    "        val_3 = X_train3[val_idx]\n",
    "        val_4 = X_train4[val_idx]\n",
    "        val_y = labels[val_idx]\n",
    "#         ckpt_path = './logtianchi/'+ model_list[n_fold]\n",
    "#         print(ckpt_path)\n",
    "        model = get_model()\n",
    "        if n_fold == 0:\n",
    "            print(model.summary())\n",
    "        print(n_fold)\n",
    "        \n",
    "\n",
    "        ckpt_path = './log/qrf2cv_'+str(n_fold)+'_weights-{val_loss:.4f}.hdf5'\n",
    "        \n",
    "\n",
    "        best_score = 1000\n",
    "        best_iter = 0\n",
    "        for i in range(10):\n",
    "            model.fit([train_1,train_2,train_3,train_4],train_y+np.random.uniform(-1,1,(len(train_y,))), \n",
    "                      validation_data=([val_1,val_2,val_3,val_4],val_y), \n",
    "                      epochs=1, \n",
    "                      batch_size=1024)\n",
    "            score = model.evaluate([val_1,val_2,val_3,val_4],val_y,batch_size=1024)[0]\n",
    "            print(score)\n",
    "            if score<best_score:\n",
    "                best_score = score\n",
    "                best_iter = i\n",
    "                model.save_weights('./log/qrf2cv'+str(n_fold)+'.h5')\n",
    "            if i-best_iter>3:\n",
    "                break\n",
    "        model.load_weights('./log/qrf2cv'+str(n_fold)+'.h5')\n",
    "        second_level_train_set[val_idx] = model.predict([val_1, val_2,val_3,val_4], batch_size=1024)[:, 0]\n",
    "        test_nfolds_sets[:,n_fold] = model.predict([X_test1, X_test2, X_test3, X_test4], batch_size=1024)[:, 0]\n",
    "    \n",
    "    \"---save---\"\n",
    "    with open('./data/qrf2_test_nfolds_sets3.txt', 'wb') as data_file:\n",
    "        pickle.dump(test_nfolds_sets, data_file)\n",
    "\n",
    "    second_level_test_set[:] = test_nfolds_sets.mean(axis=1)\n",
    "\n",
    "    result = second_level_test_set\n",
    "    \n",
    "    return second_level_train_set, second_level_test_set, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 48)        221232      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 48)        221232      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 128)       2696192     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 48)        192         embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 48)        192         embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 128)          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20)           80          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 48)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 48)           0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          2688        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 48)           0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 400)          0           batch_normalization_5[0][0]      \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          205312      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          262656      dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            513         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,873,457\n",
      "Trainable params: 3,872,969\n",
      "Non-trainable params: 488\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "0\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 379s 31us/step - loss: 39.8439 - root_mean_squared_error: 39.8439 - val_loss: 37.2782 - val_root_mean_squared_error: 37.2782\n",
      "1373356/1373356 [==============================] - 9s 7us/step\n",
      "37.27822906972874\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 395s 32us/step - loss: 37.7663 - root_mean_squared_error: 37.7663 - val_loss: 36.6366 - val_root_mean_squared_error: 36.6366\n",
      "1373356/1373356 [==============================] - 8s 6us/step\n",
      "36.63657337453475\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 397s 32us/step - loss: 37.0925 - root_mean_squared_error: 37.0925 - val_loss: 36.3703 - val_root_mean_squared_error: 36.3703\n",
      "1373356/1373356 [==============================] - 10s 7us/step\n",
      "36.37033681006298\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 319s 26us/step - loss: 36.6256 - root_mean_squared_error: 36.6256 - val_loss: 36.0742 - val_root_mean_squared_error: 36.0742\n",
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "36.074220436731295\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 245s 20us/step - loss: 36.2442 - root_mean_squared_error: 36.2442 - val_loss: 36.0019 - val_root_mean_squared_error: 36.0019\n",
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "36.0019358472287\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 246s 20us/step - loss: 35.9514 - root_mean_squared_error: 35.9514 - val_loss: 36.0456 - val_root_mean_squared_error: 36.0456\n",
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "36.04555989434215\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 256s 21us/step - loss: 35.6782 - root_mean_squared_error: 35.6782 - val_loss: 35.9412 - val_root_mean_squared_error: 35.9412\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "35.94122809666358\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 249s 20us/step - loss: 35.4380 - root_mean_squared_error: 35.4380 - val_loss: 35.9728 - val_root_mean_squared_error: 35.9728\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "35.97280980010065\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 250s 20us/step - loss: 35.2346 - root_mean_squared_error: 35.2346 - val_loss: 36.0198 - val_root_mean_squared_error: 36.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "36.019820928136824\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 249s 20us/step - loss: 35.0281 - root_mean_squared_error: 35.0281 - val_loss: 36.0560 - val_root_mean_squared_error: 36.0560\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.05599449401948\n",
      "1\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 264s 21us/step - loss: 39.8507 - root_mean_squared_error: 39.8507 - val_loss: 38.4269 - val_root_mean_squared_error: 38.4269\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "38.426878391371964\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 253s 20us/step - loss: 37.7920 - root_mean_squared_error: 37.7920 - val_loss: 36.7874 - val_root_mean_squared_error: 36.7874\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.78743837659825\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 250s 20us/step - loss: 37.1183 - root_mean_squared_error: 37.1183 - val_loss: 36.4791 - val_root_mean_squared_error: 36.4791\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.479100220881264\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 251s 20us/step - loss: 36.6461 - root_mean_squared_error: 36.6461 - val_loss: 36.2177 - val_root_mean_squared_error: 36.2177\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.217674820888774\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 251s 20us/step - loss: 36.2794 - root_mean_squared_error: 36.2794 - val_loss: 35.9526 - val_root_mean_squared_error: 35.9526\n",
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "35.95264074501503\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 252s 20us/step - loss: 35.9711 - root_mean_squared_error: 35.9711 - val_loss: 36.0451 - val_root_mean_squared_error: 36.0451\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.04509553426019\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 260s 21us/step - loss: 35.7060 - root_mean_squared_error: 35.7060 - val_loss: 36.0274 - val_root_mean_squared_error: 36.0274\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "36.027443583175874\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 258s 21us/step - loss: 35.4661 - root_mean_squared_error: 35.4661 - val_loss: 35.9614 - val_root_mean_squared_error: 35.9614\n",
      "1373356/1373356 [==============================] - 6s 4us/step\n",
      "35.96140874192297\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 264s 21us/step - loss: 35.2571 - root_mean_squared_error: 35.2571 - val_loss: 36.0289 - val_root_mean_squared_error: 36.0289\n",
      "1373356/1373356 [==============================] - 7s 5us/step\n",
      "36.028940913988585\n",
      "2\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 266s 22us/step - loss: 39.8496 - root_mean_squared_error: 39.8496 - val_loss: 37.4171 - val_root_mean_squared_error: 37.4171\n",
      "1373356/1373356 [==============================] - 6s 5us/step\n",
      "37.41712861362207\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 271s 22us/step - loss: 37.7956 - root_mean_squared_error: 37.7956 - val_loss: 36.6556 - val_root_mean_squared_error: 36.6556\n",
      "1373356/1373356 [==============================] - 7s 5us/step\n",
      "36.655582942009744\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 269s 22us/step - loss: 37.1436 - root_mean_squared_error: 37.1436 - val_loss: 36.3510 - val_root_mean_squared_error: 36.3510\n",
      "1373356/1373356 [==============================] - 7s 5us/step\n",
      "36.350986458425055\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 271s 22us/step - loss: 36.6973 - root_mean_squared_error: 36.6973 - val_loss: 36.3257 - val_root_mean_squared_error: 36.3257\n",
      "1373356/1373356 [==============================] - 7s 5us/step\n",
      "36.32570573799102\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 402s 32us/step - loss: 36.4686 - root_mean_squared_error: 36.4686 - val_loss: 36.3702 - val_root_mean_squared_error: 36.3702\n",
      "1373356/1373356 [==============================] - 12s 8us/step\n",
      "36.37017958020312\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 581s 47us/step - loss: 36.2338 - root_mean_squared_error: 36.2338 - val_loss: 36.4503 - val_root_mean_squared_error: 36.4503\n",
      "1373356/1373356 [==============================] - 19s 14us/step\n",
      "36.45029403721722\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 580s 47us/step - loss: 35.9297 - root_mean_squared_error: 35.9297 - val_loss: 36.2328 - val_root_mean_squared_error: 36.2328\n",
      "1373356/1373356 [==============================] - 19s 14us/step\n",
      "36.2328204941706\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 574s 46us/step - loss: 35.7114 - root_mean_squared_error: 35.7114 - val_loss: 36.8344 - val_root_mean_squared_error: 36.8344\n",
      "1373356/1373356 [==============================] - 16s 12us/step\n",
      "36.834384531120094\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 572s 46us/step - loss: 35.5309 - root_mean_squared_error: 35.5309 - val_loss: 36.6004 - val_root_mean_squared_error: 36.6004\n",
      "1373356/1373356 [==============================] - 16s 12us/step\n",
      "36.6003534295912\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/1\n",
      "12360197/12360197 [==============================] - 570s 46us/step - loss: 35.3316 - root_mean_squared_error: 35.3316 - val_loss: 36.5235 - val_root_mean_squared_error: 36.5235\n",
      "1373356/1373356 [==============================] - 17s 12us/step\n",
      "36.523528116289796\n",
      "3\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 572s 46us/step - loss: 39.9458 - root_mean_squared_error: 39.9458 - val_loss: 37.2291 - val_root_mean_squared_error: 37.2291\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "37.229147245016\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 571s 46us/step - loss: 37.8928 - root_mean_squared_error: 37.8928 - val_loss: 37.3053 - val_root_mean_squared_error: 37.3053\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "37.305276356341786\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 571s 46us/step - loss: 37.2265 - root_mean_squared_error: 37.2265 - val_loss: 36.4262 - val_root_mean_squared_error: 36.4262\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.42623881520612\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 569s 46us/step - loss: 36.7659 - root_mean_squared_error: 36.7659 - val_loss: 36.2908 - val_root_mean_squared_error: 36.2908\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "36.29078938918244\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 577s 47us/step - loss: 36.4124 - root_mean_squared_error: 36.4124 - val_loss: 36.1224 - val_root_mean_squared_error: 36.1224\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.122423994262924\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 572s 46us/step - loss: 36.1177 - root_mean_squared_error: 36.1177 - val_loss: 36.0953 - val_root_mean_squared_error: 36.0953\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.09533450930232\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 572s 46us/step - loss: 35.8470 - root_mean_squared_error: 35.8470 - val_loss: 36.1815 - val_root_mean_squared_error: 36.1815\n",
      "1373355/1373355 [==============================] - 21s 15us/step\n",
      "36.18153190354611\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 630s 51us/step - loss: 35.6214 - root_mean_squared_error: 35.6214 - val_loss: 36.5139 - val_root_mean_squared_error: 36.5139\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.51387904321706\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 572s 46us/step - loss: 35.4100 - root_mean_squared_error: 35.4100 - val_loss: 36.1108 - val_root_mean_squared_error: 36.1108\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.110761801155604\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 565s 46us/step - loss: 35.2519 - root_mean_squared_error: 35.2519 - val_loss: 37.1883 - val_root_mean_squared_error: 37.1883\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "37.18834361312216\n",
      "4\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 564s 46us/step - loss: 39.9352 - root_mean_squared_error: 39.9352 - val_loss: 37.3321 - val_root_mean_squared_error: 37.3321\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.332134463410526\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 565s 46us/step - loss: 37.9072 - root_mean_squared_error: 37.9072 - val_loss: 36.7685 - val_root_mean_squared_error: 36.7685\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.76848409578068\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 563s 46us/step - loss: 37.2145 - root_mean_squared_error: 37.2145 - val_loss: 36.3098 - val_root_mean_squared_error: 36.3098\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.309837813792136\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 563s 46us/step - loss: 36.7564 - root_mean_squared_error: 36.7564 - val_loss: 36.2415 - val_root_mean_squared_error: 36.2415\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.24148518088912\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 567s 46us/step - loss: 36.4198 - root_mean_squared_error: 36.4198 - val_loss: 36.1690 - val_root_mean_squared_error: 36.1690\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.169019062827715\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 566s 46us/step - loss: 36.1144 - root_mean_squared_error: 36.1144 - val_loss: 36.0603 - val_root_mean_squared_error: 36.0603\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.060256572073015\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 564s 46us/step - loss: 35.8565 - root_mean_squared_error: 35.8565 - val_loss: 36.1107 - val_root_mean_squared_error: 36.1107\n",
      "1373355/1373355 [==============================] - 17s 13us/step\n",
      "36.11067090769885\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 561s 45us/step - loss: 35.6096 - root_mean_squared_error: 35.6096 - val_loss: 36.6129 - val_root_mean_squared_error: 36.6129: - ETA: 3s - loss: 35.\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.612896509706374\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 557s 45us/step - loss: 35.3941 - root_mean_squared_error: 35.3941 - val_loss: 35.9120 - val_root_mean_squared_error: 35.9120\n",
      "1373355/1373355 [==============================] - 15s 11us/step\n",
      "35.91196844078307\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 45us/step - loss: 35.2188 - root_mean_squared_error: 35.2188 - val_loss: 36.3441 - val_root_mean_squared_error: 36.3441\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.34412072952697\n",
      "5\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 615s 50us/step - loss: 39.8978 - root_mean_squared_error: 39.8978 - val_loss: 37.4045 - val_root_mean_squared_error: 37.4045\n",
      "1373355/1373355 [==============================] - 21s 15us/step\n",
      "37.404486505475845\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 548s 44us/step - loss: 37.8681 - root_mean_squared_error: 37.8681 - val_loss: 36.8553 - val_root_mean_squared_error: 36.8553\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.85534142455179\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 566s 46us/step - loss: 37.2006 - root_mean_squared_error: 37.2006 - val_loss: 36.5616 - val_root_mean_squared_error: 36.5616\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.56163689963857\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 46us/step - loss: 36.7550 - root_mean_squared_error: 36.7550 - val_loss: 36.3110 - val_root_mean_squared_error: 36.3110\n",
      "1373355/1373355 [==============================] - 17s 13us/step\n",
      "36.31104298662961\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 46us/step - loss: 36.4610 - root_mean_squared_error: 36.4610 - val_loss: 37.0329 - val_root_mean_squared_error: 37.0329\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "37.032857224799514\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 45us/step - loss: 36.2080 - root_mean_squared_error: 36.2080 - val_loss: 37.0797 - val_root_mean_squared_error: 37.0797\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "37.07970777493035\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 563s 46us/step - loss: 35.9291 - root_mean_squared_error: 35.9291 - val_loss: 36.6330 - val_root_mean_squared_error: 36.6330\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.63301112073475\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 567s 46us/step - loss: 35.7060 - root_mean_squared_error: 35.7060 - val_loss: 36.7772 - val_root_mean_squared_error: 36.7772\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.77717596658403\n",
      "6\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 577s 47us/step - loss: 39.9492 - root_mean_squared_error: 39.9492 - val_loss: 37.2980 - val_root_mean_squared_error: 37.2980\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.29797034943215\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 563s 46us/step - loss: 37.8991 - root_mean_squared_error: 37.8991 - val_loss: 36.6639 - val_root_mean_squared_error: 36.6639\n",
      "1373355/1373355 [==============================] - 17s 13us/step\n",
      "36.663857734598764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 569s 46us/step - loss: 37.2436 - root_mean_squared_error: 37.2436 - val_loss: 36.3936 - val_root_mean_squared_error: 36.3936\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.39364954992462\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 568s 46us/step - loss: 36.8000 - root_mean_squared_error: 36.8000 - val_loss: 36.2894 - val_root_mean_squared_error: 36.2894\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.289380387300106\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 567s 46us/step - loss: 36.4607 - root_mean_squared_error: 36.4607 - val_loss: 36.4193 - val_root_mean_squared_error: 36.4193\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "36.419299931266494\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 624s 50us/step - loss: 36.1678 - root_mean_squared_error: 36.1678 - val_loss: 36.1632 - val_root_mean_squared_error: 36.1632\n",
      "1373355/1373355 [==============================] - 21s 15us/step\n",
      "36.163150134720034\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 556s 45us/step - loss: 35.9011 - root_mean_squared_error: 35.9011 - val_loss: 36.0268 - val_root_mean_squared_error: 36.0268\n",
      "1373355/1373355 [==============================] - 17s 13us/step\n",
      "36.02684624901012\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 557s 45us/step - loss: 35.6892 - root_mean_squared_error: 35.6892 - val_loss: 36.1869 - val_root_mean_squared_error: 36.1869\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.18694183172006\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 45us/step - loss: 35.5948 - root_mean_squared_error: 35.5948 - val_loss: 36.8223 - val_root_mean_squared_error: 36.8223\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.82231661736861\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 545s 44us/step - loss: 35.4138 - root_mean_squared_error: 35.4138 - val_loss: 36.6021 - val_root_mean_squared_error: 36.6021\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "36.60206797769323\n",
      "7\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 570s 46us/step - loss: 39.8964 - root_mean_squared_error: 39.8964 - val_loss: 38.5489 - val_root_mean_squared_error: 38.5489\n",
      "1373355/1373355 [==============================] - 16s 11us/step\n",
      "38.54889947404237\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 545s 44us/step - loss: 37.8789 - root_mean_squared_error: 37.8789 - val_loss: 36.8036 - val_root_mean_squared_error: 36.8036\n",
      "1373355/1373355 [==============================] - 16s 11us/step\n",
      "36.80360376277126\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 530s 43us/step - loss: 37.2239 - root_mean_squared_error: 37.2239 - val_loss: 36.3205 - val_root_mean_squared_error: 36.3205\n",
      "1373355/1373355 [==============================] - 15s 11us/step\n",
      "36.320531913599304\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 531s 43us/step - loss: 36.7547 - root_mean_squared_error: 36.7547 - val_loss: 36.5933 - val_root_mean_squared_error: 36.5933\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "36.59330622214872\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 539s 44us/step - loss: 36.4254 - root_mean_squared_error: 36.4254 - val_loss: 36.2987 - val_root_mean_squared_error: 36.2987\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.29871893241528\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 544s 44us/step - loss: 36.1575 - root_mean_squared_error: 36.1575 - val_loss: 37.2783 - val_root_mean_squared_error: 37.2783\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "37.27826256143796\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 535s 43us/step - loss: 35.9223 - root_mean_squared_error: 35.9223 - val_loss: 37.0724 - val_root_mean_squared_error: 37.0724\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "37.07238216418965\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 529s 43us/step - loss: 35.7464 - root_mean_squared_error: 35.7464 - val_loss: 37.0728 - val_root_mean_squared_error: 37.0728\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.072833633196474\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 598s 48us/step - loss: 35.5236 - root_mean_squared_error: 35.5236 - val_loss: 36.8754 - val_root_mean_squared_error: 36.8754\n",
      "1373355/1373355 [==============================] - 22s 16us/step\n",
      "36.8754012698707\n",
      "8\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 533s 43us/step - loss: 39.9439 - root_mean_squared_error: 39.9439 - val_loss: 38.1202 - val_root_mean_squared_error: 38.1202\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "38.12022619804043\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 517s 42us/step - loss: 37.8889 - root_mean_squared_error: 37.8889 - val_loss: 37.6265 - val_root_mean_squared_error: 37.6265\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.62646601725921\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 524s 42us/step - loss: 37.2588 - root_mean_squared_error: 37.2588 - val_loss: 37.2678 - val_root_mean_squared_error: 37.2678\n",
      "1373355/1373355 [==============================] - 16s 11us/step\n",
      "37.2678145208664\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 529s 43us/step - loss: 36.8008 - root_mean_squared_error: 36.8008 - val_loss: 37.5804 - val_root_mean_squared_error: 37.5804 loss: 36.8011 - root_mean_squared_error: 36.\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.580415170625535\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 528s 43us/step - loss: 36.4559 - root_mean_squared_error: 36.4559 - val_loss: 36.9152 - val_root_mean_squared_error: 36.9152\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "36.91523397418812\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 528s 43us/step - loss: 36.2238 - root_mean_squared_error: 36.2238 - val_loss: 37.2585 - val_root_mean_squared_error: 37.2585\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.25846844588817\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 530s 43us/step - loss: 36.0167 - root_mean_squared_error: 36.0167 - val_loss: 36.7899 - val_root_mean_squared_error: 36.7899\n",
      "1373355/1373355 [==============================] - 16s 11us/step\n",
      "36.78989838046299\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 527s 43us/step - loss: 35.8345 - root_mean_squared_error: 35.8345 - val_loss: 36.7012 - val_root_mean_squared_error: 36.7012\n",
      "1373355/1373355 [==============================] - 15s 11us/step\n",
      "36.701155094988756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 521s 42us/step - loss: 35.6675 - root_mean_squared_error: 35.6675 - val_loss: 36.8548 - val_root_mean_squared_error: 36.8548\n",
      "1373355/1373355 [==============================] - 15s 11us/step\n",
      "36.85484627176917\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 511s 41us/step - loss: 35.4669 - root_mean_squared_error: 35.4669 - val_loss: 36.6343 - val_root_mean_squared_error: 36.6343\n",
      "1373355/1373355 [==============================] - 15s 11us/step\n",
      "36.63433715676736\n",
      "9\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 548s 44us/step - loss: 39.8604 - root_mean_squared_error: 39.8604 - val_loss: 37.2742 - val_root_mean_squared_error: 37.2742\n",
      "1373355/1373355 [==============================] - 16s 12us/step\n",
      "37.274192519894335\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 568s 46us/step - loss: 37.8236 - root_mean_squared_error: 37.8236 - val_loss: 37.4811 - val_root_mean_squared_error: 37.4811\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "37.48109588614158\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 574s 46us/step - loss: 37.2289 - root_mean_squared_error: 37.2289 - val_loss: 37.2847 - val_root_mean_squared_error: 37.2847\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "37.28469843148068\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 609s 49us/step - loss: 36.7607 - root_mean_squared_error: 36.7607 - val_loss: 36.7848 - val_root_mean_squared_error: 36.7848\n",
      "1373355/1373355 [==============================] - 23s 16us/step\n",
      "36.784751048423594\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 562s 46us/step - loss: 36.4297 - root_mean_squared_error: 36.4297 - val_loss: 36.9561 - val_root_mean_squared_error: 36.9561\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.956126460511506\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 566s 46us/step - loss: 36.1908 - root_mean_squared_error: 36.1908 - val_loss: 36.8901 - val_root_mean_squared_error: 36.8901\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.890061266282146\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 569s 46us/step - loss: 35.9305 - root_mean_squared_error: 35.9305 - val_loss: 36.5802 - val_root_mean_squared_error: 36.5802\n",
      "1373355/1373355 [==============================] - 19s 14us/step\n",
      "36.58024942808532\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 588s 48us/step - loss: 35.7188 - root_mean_squared_error: 35.7188 - val_loss: 36.6529 - val_root_mean_squared_error: 36.6529\n",
      "1373355/1373355 [==============================] - 17s 12us/step\n",
      "36.652923860043735\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 589s 48us/step - loss: 35.5334 - root_mean_squared_error: 35.5334 - val_loss: 36.4103 - val_root_mean_squared_error: 36.4103\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.410305829833554\n",
      "Train on 12360198 samples, validate on 1373355 samples\n",
      "Epoch 1/1\n",
      "12360198/12360198 [==============================] - 577s 47us/step - loss: 35.3576 - root_mean_squared_error: 35.3576 - val_loss: 36.6301 - val_root_mean_squared_error: 36.6301\n",
      "1373355/1373355 [==============================] - 18s 13us/step\n",
      "36.63005907428483\n"
     ]
    }
   ],
   "source": [
    "train_sets = []\n",
    "test_sets = []\n",
    "train_set, test_set, result = get_stacking(X_train1, X_train2, X_train3, X_train4, y_train, n_folds=10)\n",
    "train_sets.append(train_set)\n",
    "test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13733553, 1) (490380, 1)\n"
     ]
    }
   ],
   "source": [
    "meta_train = np.concatenate([result_set.reshape(-1,1) for result_set in train_sets], axis=1)\n",
    "meta_test = np.concatenate([y_test_set.reshape(-1,1) for y_test_set in test_sets], axis=1)\n",
    "print(meta_train.shape, meta_test.shape)\n",
    "\n",
    "\"---save---\"\n",
    "with open('./data/meta_train_nn_qrf2.txt', 'wb') as data_file:\n",
    "    pickle.dump(meta_train, data_file)\n",
    "with open('./data/meta_test_nn_qrf2.txt', 'wb') as data_file:\n",
    "    pickle.dump(meta_test, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([155.27383423, 225.86791992,  93.46902466, ..., 134.73045349,\n",
       "       368.41989136, 125.18015289])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109.02749786, 129.785672  , 133.44480896, ...,  90.29129028,\n",
       "        62.36225891, 198.12910919])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zuhe(line):\n",
    "    line['hour'] = line['hour'].astype(str)\n",
    "    line['weekday'] = line['weekday'].astype(str)\n",
    "    line['s_ij'] = line['s_ij'].astype(str)\n",
    "    line['e_ij'] = line['e_ij'].astype(str)\n",
    "\n",
    "#     line['is_peek'] = line['is_peek'].astype(str)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(str)\n",
    "                                   \n",
    "    line['hour_weekday'] = line['hour'] + line['weekday']\n",
    "    line['hour_crowd'] = line['hour'] + line['is_crowd']\n",
    "    line['hour_s'] = line['hour'] + line['s_ij']\n",
    "    line['hour_e'] = line['hour'] + line['e_ij']\n",
    "\n",
    "    line['hour'] = line['hour'].astype(int)\n",
    "#     line['is_peek'] = line['is_peek'].astype(int)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(int)\n",
    "    line['weekday'] = line['weekday'].astype(int)\n",
    "    line['s_ij'] = line['s_ij'].astype(int)\n",
    "    line['e_ij'] = line['e_ij'].astype(int)\n",
    "    \n",
    "    line['hour_weekday'] = line['hour_weekday'].astype(int)\n",
    "    line['hour_crowd'] = line['hour_crowd'].astype(int)\n",
    "    line['hour_s'] = line['hour_s'].astype(int)\n",
    "    line['hour_e'] = line['hour_e'].astype(int)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Distance', 'hour', 'is_peek', 'weekday', 'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'h_aver_diff', 'h_aver_d', 'h_aver_v', 'is_crowd', 's_ij', 'e_ij', 'grid_aver_diff', 'grid_aver_d', 'hour_weekday', 'hour_crowd', 'hour_s', 'hour_e']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kawayi-4/anaconda3/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test-id4-crowd-grid4.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "test = zuhe(test)\n",
    "test = test[['ID', 'new_dist',  'O_LINENO', 'O_UP', 'Source_Station', 'Target_Station',\n",
    "       'Distance', 'distance2', 'O_TIME', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'TERMINALNO', \n",
    "       'is_crowd', 's_ij', 'e_ij','grid_aver_diff', 'grid_aver_d', 'hour_weekday', 'hour_crowd', 'hour_s', 'hour_e']]\n",
    "test.columns=['ID', 'Distance',  'O_LINENO', 'O_UP', 'Source_Station', 'Target_Station',\n",
    "       'Distance1', 'distance2', 'O_TIME', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'TERMINALNO', \n",
    "       'is_crowd', 's_ij', 'e_ij','grid_aver_diff', 'grid_aver_d', 'hour_weekday', 'hour_crowd', 'hour_s', 'hour_e']\n",
    "col1 = [c for c in test if\n",
    "       c not in ['Unnamed: 0','ID2' , 's_x', 's_y', 'e_x', 'e_y','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time','Distance1', 'distance2','TERMINALNO', 'new_dist']]\n",
    "print(col1)\n",
    "\n",
    "test['pred1'] = pred\n",
    "test['pred2'] = pred\n",
    "\n",
    "sub1 = test[['O_LINENO','TERMINALNO', 'O_UP','Source_Station','Target_Station','O_TIME','pred1','pred2','Distance','Distance1']]\n",
    "sub1['O_TIME'] = pd.to_datetime(sub1['O_TIME'],format='%Y-%m-%d %H:%M:%S')\n",
    "sub1.columns = ['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime','pred1','pred2','Distance','Distance1']\n",
    "sub1 = sub1.reset_index()\n",
    "del sub1['index']\n",
    "\n",
    "sub=pd.read_csv(\"./toBePredicted_0607_segment.csv\", sep=\",\")\n",
    "sub['realTime'] = pd.to_datetime(sub['realTime'],format='%Y-%m-%d %H:%M:%S')\n",
    "sub2 = sub[['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime','distance']]\n",
    "sub2=pd.merge(sub2,sub1,on=['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime'],how='left')\n",
    "\n",
    "\n",
    "sub2['div_dist'] = sub2['Distance'] / sub2['Distance1']\n",
    "sub2['new_pred'] = sub2['div_dist'] * sub2['pred1']\n",
    "\n",
    "import math\n",
    "for i in range(sub2.shape[0]):\n",
    "    s = sub2.iloc[i]\n",
    "    if math.isnan(s['div_dist']):\n",
    "        sub2.loc[i,'new_pred'] = s['pred1']\n",
    "        \n",
    "sub2.to_csv('./qrf_toBePredicted_0807_result.csv',sep=\",\",index=False)#0605 29.2467\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
