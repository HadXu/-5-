{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import *\n",
    "import datetime\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid\n",
    "根据地理信息划分格子，统计格子上历史平均时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./history/\"\n",
    "history = pd.DataFrame()\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for file in tqdm(files):\n",
    "        s = os.path.join(root,file)\n",
    "        print (s)\n",
    "        line = file.split('_')[0]\n",
    "        with open(s, 'rb') as data_file:\n",
    "            h = pickle.load(data_file).reset_index()\n",
    "        h['Line'] = line\n",
    "        h['is_rain'] = file.split('_')[1]\n",
    "        h['is_workday'] = file.split('_')[2]\n",
    "        h['is_peek'] = file.split('_')[3].split('.')[0]\n",
    "\n",
    "        history = pd.concat([history,h])\n",
    "with open('./data/full_history', 'wb') as data_file:\n",
    "    pickle.dump(history, data_file)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_pandas\n",
    "import math\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def read_station_loc(line, on, start):\n",
    "    path = './station/' + str(line) + '.txt'\n",
    "    if os.path.exists(path):\n",
    "        bus1 = pd.read_table(path, header=None, sep=',', encoding='utf-8')\n",
    "        bus1.columns = [\"O_UP\", \"Source_Station\", \"O_LATITUDE\", \"O_LONGITUDE\"]\n",
    "        b = bus1[(bus1['O_UP'] == on) & (bus1['Source_Station'] == start)]\n",
    "        if b.shape[0] > 0:\n",
    "            return str([b.iloc[0]['O_LATITUDE'], b.iloc[0]['O_LONGITUDE']])\n",
    "        else:\n",
    "            return str([-1, -1])\n",
    "    else:\n",
    "        return str([-1, -1])\n",
    "\n",
    "#38.65936 40.07771\n",
    "#116.917 117.97901\n",
    "max_x = 40.0777#max(test2['s_x'].max(),test2['e_x'].max()) + 0.00001\n",
    "min_x = 38.6325#min(test2['s_x'].min(),test2['e_x'].min())\n",
    "max_y = 118.16#max(test2['s_y'].max(),test2['e_y'].max()) + 0.00001\n",
    "min_y = 116.900#min(test2['s_y'].min(),test2['e_y'].min())\n",
    "lx = (max_x - min_x) / 50\n",
    "ly = (max_y - min_y) / 33\n",
    "print(min_x, max_x)\n",
    "print(min_y, max_y)\n",
    "print(lx, ly)\n",
    "\n",
    "\n",
    "def get_ij(x, y):\n",
    "    i = math.floor((x - min_x) / lx)\n",
    "    j = math.floor((y - min_y) / ly)\n",
    "    num = i * 33 + (j + 1)\n",
    "    return num\n",
    "\n",
    "\n",
    "# progress_apply\n",
    "def process(train_id):\n",
    "    train_id['Source_loc'] = train_id.progress_apply(lambda x: read_station_loc(x['Line'], x['O_UP'], x['Source_Station']), axis=1)\n",
    "    train_id['end_loc'] = train_id.progress_apply(lambda x: read_station_loc(x['Line'], x['O_UP'], x['Target_Station']), axis=1)\n",
    "    train_id['s_x'] = train_id.Source_loc.apply(lambda x: x[1:-1].split(',')[0].replace(' ', \"\"))\n",
    "    train_id['s_y'] = train_id.Source_loc.apply(lambda x: x[1:-1].split(',')[1].replace(' ', \"\"))\n",
    "    train_id['e_x'] = train_id.end_loc.apply(lambda x: x[1:-1].split(',')[0].replace(' ', \"\"))\n",
    "    train_id['e_y'] = train_id.end_loc.apply(lambda x: x[1:-1].split(',')[1].replace(' ', \"\"))\n",
    "\n",
    "    train_id['s_x'] = train_id.s_x.str.extract('(\\d+\\.\\d+)', expand=False)\n",
    "    train_id['s_y'] = train_id.s_y.str.extract('(\\d+\\.\\d+)', expand=False)\n",
    "    train_id['e_x'] = train_id.e_x.str.extract('(\\d+\\.\\d+)', expand=False)\n",
    "    train_id['e_y'] = train_id.e_y.str.extract('(\\d+\\.\\d+)', expand=False)\n",
    "\n",
    "    train_id['s_x'] = train_id.s_x.astype(np.float32)\n",
    "    train_id['s_y'] = train_id.s_y.astype(np.float32)\n",
    "    train_id['e_x'] = train_id.e_x.astype(np.float32)\n",
    "    train_id['e_y'] = train_id.e_y.astype(np.float32)\n",
    "\n",
    "    train_id['s_ij'] = train_id.progress_apply(\n",
    "        lambda x: get_ij(x['s_x'], x['s_y']) if (np.all(pd.notnull(x['s_x'])) and np.all(pd.notnull(x['s_y']))) else -1,\n",
    "        axis=1)\n",
    "    train_id['e_ij'] = train_id.progress_apply(\n",
    "        lambda x: get_ij(x['e_x'], x['e_y']) if (np.all(pd.notnull(x['e_x'])) and np.all(pd.notnull(x['e_y']))) else -1,\n",
    "        axis=1)\n",
    "    del train_id['Source_loc'], train_id['end_loc']\n",
    "    return train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/full_history', 'rb') as data_file:\n",
    "    hi = pickle.load(data_file)\n",
    "hi = process(hi)\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/full_history_plus', 'wb') as data_file:\n",
    "    pickle.dump(hi, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train-id4-crowd-grid3.txt', 'rb') as data_file:\n",
    "    line = pickle.load(data_file)\n",
    "with open('./data/test-id4-crowd-grid3.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "\n",
    "def get_grid_history(l,o,s,t,w,p,r,s,e):\n",
    "    b = hi[(hi['Line']==l)&(hi['O_UP']==o)&(hi['source_id']==s)&(hi['target_id']==t)&(hi['is_workday']==w)&(hi['is_peek']==p)&(hi['is_rain']==r)&(hi['s_ij']==s)&(hi['e_ij']==e)]#\n",
    "    if b.shape[0] > 0:\n",
    "        return b.iloc[0]\n",
    "    else :\n",
    "        dic = {'Distance':[-1],'Diff_Time':[-1]}\n",
    "        x = pd.DataFrame(dic)\n",
    "        return x.iloc[0]\n",
    "    \n",
    "tmp = train.progress_apply(lambda x : get_grid_history(x['O_LINENO'],x['O_UP'],x['Source_Station_encode'],x['Target_Station_encode'],x['is_workday'],x['is_peek'],x['s_ij'],x['e_ij']), axis=1)\n",
    "['grid_aver_diff'] = tmp['Diff_Time']\n",
    "train['grid_aver_d'] = tmp['Distance']\n",
    "train\n",
    "\n",
    "\n",
    "tmp1 = test.progress_apply(lambda x : get_grid_history(x['O_LINENO'],x['O_UP'],x['Source_Station'],x['Target_Station'],x['is_workday'],x['is_peek'],x['s_ij'],x['e_ij']), axis=1)\n",
    "test['grid_aver_diff'] = tmp1['Diff_Time']\n",
    "test['grid_aver_d'] = tmp1['Distance']\n",
    "test\n",
    "with open('./data/test-id4-crowd-grid3.txt', 'wb') as data_file:\n",
    "    pickle.dump(test, data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID\n",
    "拼接线路-上下行-站点编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfeature(a,b,c,d):\n",
    "    if c < 10:\n",
    "        c = '0'+str(c)\n",
    "    if d < 10:\n",
    "        d = '0'+str(d)\n",
    "    return str(a)+str(b)+str(c)+str(d)\n",
    "train['ID'] = train.apply(lambda x: idfeature(x['O_LINENO'],x['O_UP'],x['Source_Station'],x['Target_Station']),axis=1)\n",
    "train = train[['ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'Distance',\n",
    "       'O_TIME', 'aver_v', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'Diff_Time']]\n",
    "test['ID'] = test.apply(lambda x: idfeature(x['O_LINENO'],x['O_UP'],x['Source_Station'],x['Target_Station']),axis=1)\n",
    "test = test[['ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'Distance',\n",
    "       'O_TIME', 'aver_v', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'Diff_Time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train-id4-crowd-grid3.txt', 'wb') as data_file:\n",
    "    pickle.dump(train, data_file)\n",
    "with open('./data/test-id4-crowd-grid3.txt', 'wb') as data_file:\n",
    "    pickle.dump(test, data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
