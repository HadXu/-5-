{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b418-xiwei/anaconda3/envs/dl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/b418-xiwei/anaconda3/envs/dl/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14223933,)\n",
      "(14223933,)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Flatten, Input, concatenate\n",
    "import pickle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)+1e-10, axis=-1))\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n",
    "\n",
    "ckpt_path = './log/weights-{val_loss:.4f}.hdf5'\n",
    "ckpt = ModelCheckpoint(ckpt_path,\n",
    "                       monitor='val_loss', \n",
    "                       verbose=1, \n",
    "                       save_best_only=True, \n",
    "                       mode='min')\n",
    "def zuhe(line):\n",
    "    line['hour'] = line['hour'].astype(str)\n",
    "    line['weekday'] = line['weekday'].astype(str)\n",
    "#     line['is_peek'] = line['is_peek'].astype(str)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(str)\n",
    "                                   \n",
    "    line['hour_weekday'] = line['hour'] + line['weekday']\n",
    "    line['hour_crowd'] = line['hour'] + line['is_crowd']\n",
    "    \n",
    "    line['hour'] = line['hour'].astype(int)\n",
    "#     line['is_peek'] = line['is_peek'].astype(int)\n",
    "    line['is_crowd'] = line['is_crowd'].astype(int)\n",
    "    line['weekday'] = line['weekday'].astype(int)\n",
    "    \n",
    "    line['hour_weekday'] = line['hour_weekday'].astype(int)\n",
    "    line['hour_crowd'] = line['hour_crowd'].astype(int)\n",
    "    return line\n",
    "\n",
    "with open('./data/train-id3-crowd-grid2.txt', 'rb') as data_file:\n",
    "    train = pickle.load(data_file)\n",
    "    #训练验证都划分\n",
    "    #900 29 26 #800 27.9 25.9 #700 27.5 25.3 #27.4 24.8 #26.4 24.08 #23 21 #(90)250 21 19.5 #(80)17. 16.5\n",
    "    #训练划分 验证不划分\n",
    "    #250\n",
    "train = train[(train['Diff_Time']<600)]\n",
    "train = zuhe(train)\n",
    "with open('./data/test-id3-crowd-grid2.txt', 'rb') as data_file:\n",
    "    test = pickle.load(data_file)\n",
    "test = zuhe(test)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x11 = train['ID'].as_matrix().reshape([-1,1])\n",
    "x12 = train['ID2'].as_matrix().reshape([-1,1])\n",
    "# x13 = train['e_ij'].as_matrix().reshape([-1,1])\n",
    "\n",
    "N1 = x11.shape[0]\n",
    "\n",
    "x21 = test['ID'].as_matrix().reshape([-1,1])\n",
    "x22 = test['ID2'].as_matrix().reshape([-1,1])\n",
    "# x23 = test['e_ij'].as_matrix().reshape([-1,1])\n",
    "\n",
    "N2 = x21.shape[0]\n",
    "\n",
    "x1 = np.concatenate((x11,x21))\n",
    "x1 = preprocessing.LabelEncoder().fit_transform(x1) #13963746x21567\n",
    "print(x1.shape)#(14454126, 21567)\n",
    "train['new_ID'] = x1[:N1]\n",
    "test['new_ID'] = x1[N1:]\n",
    "\n",
    "x2 = np.concatenate((x12,x22))\n",
    "x2 = preprocessing.LabelEncoder().fit_transform(x2) #13963746x21567\n",
    "print(x2.shape)#(14454126, 21567)\n",
    "train['new_ID2'] = x2[:N1]\n",
    "test['new_ID2'] = x2[N1:]\n",
    "\n",
    "# x3 = np.concatenate((x13,x23))\n",
    "# x3 = preprocessing.LabelEncoder().fit_transform(x3) #13963746x21567\n",
    "# print(x3.shape)#(14454126, 21567)\n",
    "# train['new_e_ID'] = x3[:N1]\n",
    "# test['new_e_ID'] = x3[N1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12360197, 35)\n",
      "(1373356, 35)\n"
     ]
    }
   ],
   "source": [
    "#np.unique(x2).shape\n",
    "from sklearn.utils import shuffle\n",
    "line = shuffle(train)\n",
    "train_num = int(0.9 * line.shape[0])\n",
    "train = line[:train_num]\n",
    "#!\n",
    "dev = line[train_num:]\n",
    "print(train.shape)\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new_ID'] ['new_ID2'] ['Distance', 'hour', 'is_peek', 'weekday', 'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'h_aver_diff', 'h_aver_d', 'h_aver_v', 'hour_weekday', 'hour_crowd']\n",
      "(12360197, 1) (12360197, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 256)       5490944     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 256)       1863168     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          8192        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 32, 32, 1)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   320         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4096)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          524416      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,905,665\n",
      "Trainable params: 7,905,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12360197 samples, validate on 1373356 samples\n",
      "Epoch 1/40\n",
      " 3047424/12360197 [======>.......................] - ETA: 12:25 - loss: 31.5095 - root_mean_squared_error: 31.5095"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape, Conv2D, MaxPooling2D\n",
    "col1 = ['new_ID']\n",
    "col2 = ['new_ID2']\n",
    "col3 = [c for c in train if\n",
    "       c not in ['ID2', 'new_ID2','Unnamed: 0','is_crowd', 's_ij', 'e_ij','s_x', 's_y', 'e_x', 'e_y','new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time']]\n",
    "#+gps 2 epoch 31\n",
    "X_train1 = train[col1].values\n",
    "X_train2 = train[col2].values\n",
    "X_train3 = train[col3].values\n",
    "\n",
    "y_train = train['Diff_Time'].values\n",
    "print(col1,col2,col3)\n",
    "print(X_train1.shape, X_train2.shape)\n",
    "X_dev1 = dev[col1].values\n",
    "X_dev2 = dev[col2].values\n",
    "X_dev3 = dev[col3].values\n",
    "\n",
    "y_dev = dev['Diff_Time'].values\n",
    "# print(X_dev.shape, y_dev.shape)\n",
    "\n",
    "input1 = Input(shape=(1,))\n",
    "input2 = Input(shape=(1,))\n",
    "input3 = Input(shape=(15,))\n",
    "\n",
    "x1 = Embedding(21449, 256, input_length=1)(input1)\n",
    "x1 = Flatten()(x1)\n",
    "x2 = Embedding(7278, 256, input_length=1)(input2)\n",
    "x2 = Flatten()(x2)\n",
    "x3 = Dense(units=512)(input3)\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "\n",
    "x = concatenate([x1, x2, x3])\n",
    "#CNN\n",
    "x = Reshape((32, 32, 1))(x)\n",
    "x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(1, activation=None)(x)\n",
    "model = Model(inputs=[input1, input2, input3], outputs=out)\n",
    "print(model.summary())\n",
    "# model.load_weights('./log/weights-21.7671.hdf5')\n",
    "model.compile(loss=root_mean_squared_error, optimizer='adam', metrics=[root_mean_squared_error])\n",
    "model.fit([X_train1,X_train2,X_train3], y_train, validation_data=([X_dev1,X_dev2,X_dev3], y_dev), epochs=40, batch_size=1024,callbacks=[ckpt,earlyStopping])\n",
    "# model.save(\"keras3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = ['new_ID']\n",
    "col2 = ['new_ID2']\n",
    "col3 = [c for c in test if\n",
    "       c not in ['new_ID','ID','O_LINENO', 'O_UP', 'Source_Station', 'Target_Station', 'O_TIME', 'aver_v', 'max_v',\n",
    "                 'Diff_Time','Distance1', 'distance2','TERMINALNO', 'new_dist']]\n",
    "print(col1,col2,col3)\n",
    "X_test1 = test[col1].values\n",
    "X_test2 = test[col2].values t7\n",
    "X_test3 = test[col3].values\n",
    "print(X_test1.shape,X_test2.shape,X_test3.shape)\n",
    "\n",
    "model.load_weights('./log/weights-21.7671.hdf5') #(21.7671==<0.03789)\n",
    "y_pred1 =  model.predict([X_test1,X_test2,X_test3],batch_size=1024)[:,0]\n",
    "\n",
    "test = test[['ID', 'new_dist',  'O_LINENO', 'O_UP', 'Source_Station', 'Target_Station',\n",
    "       'Distance', 'distance2', 'O_TIME', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'TERMINALNO', \n",
    "       'hour_weekday','is_crowd', 's_ij', 'e_ij','peak_workday']]\n",
    "test.columns=['ID', 'Distance',  'O_LINENO', 'O_UP', 'Source_Station', 'Target_Station',\n",
    "       'Distance1', 'distance2', 'O_TIME', 'hour', 'is_peek', 'weekday',\n",
    "       'is_workday', 'dws', 'nws', 'dts', 'nts', 'is_rain', 'max_v',\n",
    "       'h_aver_diff', 'h_aver_d', 'h_aver_v', 'TERMINALNO', \n",
    "       'hour_weekday','is_crowd', 's_ij', 'e_ij','peak_workday']\n",
    "\n",
    "test['pred1'] = y_pred1\n",
    "test['pred2'] = y_pred1\n",
    "\n",
    "sub1 = test[['O_LINENO','TERMINALNO', 'O_UP','Source_Station','Target_Station','O_TIME','pred1','pred2','Distance','Distance1']]\n",
    "sub1.columns = ['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime','pred1','pred2','Distance','Distance1']\n",
    "sub1 = sub1.reset_index()\n",
    "del sub1['index']\n",
    "\n",
    "sub=pd.read_csv(\"./toBePredicted_0607_segment.csv\", sep=\",\")\n",
    "sub['realTime'] = pd.to_datetime(sub['realTime'],format='%Y-%m-%d %H:%M:%S')\n",
    "sub2 = sub[['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime','distance']]\n",
    "sub2=pd.merge(sub2,sub1,on=['LINE','TERMINALNO','UP','pred_start_stop_ID','pred_end_stop_ID','realTime'],how='left')\n",
    "sub2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
